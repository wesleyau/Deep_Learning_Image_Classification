1. Move *.npz archives that contain 5 .npy to own folder using unix
mv *.npz ../npz_folder

2. Seperate the TX and TY Machines, put them in their own folder using unix
mv *TX* ./TX
mv *TY* ./TY

3. Run split_npy_by_class-final.py for each of the TX and TY Machines

4. Run pny_pixel_stats_final.py for each of the 5 classes for both machines to see what you should normalize the pixel intensities to.

5. Write down the numbers for each and write down the vmin and vmax values you will have to enter into the mask_image scripts for the TX and TY dataet.

5. Run mask_image_final.py on the main directory of the split image classes to mask images and standardize them for input into deep learning model

6. run PCA_vim_vmax.py and K-S test.py on both raw and masked .npy files to see if they can be combined (probably not though)

7 use txt_to_label.py to take the pngs and move them into their specific crystal folders - the txt file nees to have 3 columns id, dicom, label - i have an example in the shared folder
If you find that you are not getting the same number of folders as you should be, you have duplicate labels. Delete duplicates with the delte duplicate function in excel

8. Move unlabeled data to anothe folder and then Split the folders into pass and fail folders
mv /data/wesley/3_data_7_31_23/TX_reflect_dataset/*Unlabeled /data/wesley/3_data_7_31_23/unlabeled/tx_reflection
mv /data/wesley/3_data_7_31_23/TY_reflect_dataset/*Pass /data/wesley/3_data_7_31_23/TY_reflect_dataset/Pass
mv /data/wesley/3_data_7_31_23/TY_reflect_dataset/*Fail /data/wesley/3_data_7_31_23/TY_reflect_dataset/Fail
mv /data/wesley/3_data_7_31_23/TY_reflect_dataset/*Fail /data/wesley/3_data_7_31_23/TX_reflect_dataset/Fail

9. use split_train_val_test.py to split dataset into train and test datasets. I downsampled the passes because there are alot of passes. So I made the ratio 3:1 pass to fails

