1. Move *.npz archives that contain 5 .npy to own folder using unix
mv *.npz ../npz_folder

2. Seperate the TX and TY Machines, put them in their own folder using unix
mv *TX* ./TX
mv *TY* ./TY

3. Run split_npy_by_class-final.py for each of the TX and TY Machines

4. Run pny_pixel_stats_final.py for each of the 5 classes for both machines to see what you should normalize the pixel intensities to.

5. Write down the numbers for each and write down the vmin and vmax values you will have to enter into the mask_image scripts for the TX and TY dataet.

5. Run mask_image_final.py on the main directory of the split image classes to mask images and standardize them for input into deep learning model

6. run PCA_vim_vmax.py and K-S test.py on both raw and masked .npy files to see if they can be combined (probably not though)

7 use txt_to_label.py to take the pngs and move them into their specific crystal folders - the txt file nees to have 3 columns id, dicom, label - i have an example in the shared folder
If you find that you are not getting the same number of folders as you should be, you have duplicate labels. Delete duplicates with the delte duplicate function in excel

8. Move unlabeled data to anothe folder and then Split the folders into pass and fail folders
mv /data/wesley/3_data_7_31_23/TX_reflect_dataset/*Unlabeled /data/wesley/3_data_7_31_23/unlabeled/tx_reflection
mv /data/wesley/3_data_7_31_23/TY_reflect_dataset/*Pass /data/wesley/3_data_7_31_23/TY_reflect_dataset/Pass
mv /data/wesley/3_data_7_31_23/TY_reflect_dataset/*Fail /data/wesley/3_data_7_31_23/TY_reflect_dataset/Fail
mv /data/wesley/3_data_7_31_23/TY_reflect_dataset/*Fail /data/wesley/3_data_7_31_23/TX_reflect_dataset/Fail

9. use split_train_val_test.py to split dataset into train and test datasets. 
I downsampled the passes because there are alot of passes. So I made the ratio 4:1 pass to fails, optimally you would want to get this to 1;1

Make sure there are seperate train, val, and test folders. 
And inside each of these folders you will need to move the pass and fail crystals in their own seperate directory
In the directory of each of these folders, create a pass and fail folders and then run these unix commands
mv *Pass ./Pass
mv *Fail ./Fail

10. Run these scripts models
TX: resnet_3channel_TX_model_confidence_trainvaltest_report_8-9-23.py
TY: resnet_3channel_TY_model_confidence_trainvaltest_report_8-9-23.py

For reflection data (I have not tested these yet):
TX: resnet_3channel_TX_model_reflection_8-9-23.py
TY:resnet_3channel_TY_model_reflection_8-9-23.py

These models have an output directory that you can find in the scripts in which all the outputs will save

Some things to keep in mind when running these scripts is that there are weights that says something like this:
weights = [0.76, 0.24]  # class 0 is "Passes" and class 1 is "Fails"

I had to fiddle alot with the weights depending on what the ratio of pass to fails are in the dataset in order to find which one is best. 
I found for the current ratio of 20% of fails in the dataset, anywhere from [0.7, 0.3] to [0.77, 0.23] works best so you will probably have to rerun the model many many times.

Also depending on how the order the batches the image data when it loads the input images which is random, there can be different results. 
So you should rerun the models alot until you find an output that performs well which will indicate the the training has batched a set of images that makes it generalizable to the data.

I would just queue the model to rerun many times, multiple times for each weight as well. 
I used the "interactive-1" notebook with jupyter network within vscode to do this: https://code.visualstudio.com/docs/python/jupyter-support-py

The weights of the best model will save in the output directory.

